{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1063099648144621830\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5077532672\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4273982901815446446\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Transfer_model' from 'models' (d:\\Users\\Fons\\OneDrive - Universidad Politécnica de Madrid\\UNIVERSIDAD\\MASTER\\Segundo curso\\Primer semestre\\MLLB\\Proyecto DEEP\\MLLB-DL-Project\\models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-bdbf3ace8889>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveFigures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwrite_json\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcreate_json\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_previous_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMLP_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVGG19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTransfer_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Transfer_model' from 'models' (d:\\Users\\Fons\\OneDrive - Universidad Politécnica de Madrid\\UNIVERSIDAD\\MASTER\\Segundo curso\\Primer semestre\\MLLB\\Proyecto DEEP\\MLLB-DL-Project\\models.py)"
     ]
    }
   ],
   "source": [
    "# Import general purpose python libraries\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image # For handling the images\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "# Import different Keras functionalities\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "#from tensorflow.keras.optimizers import SGD,Adagrad\n",
    "from keras.optimizers import SGD,Adagrad\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras import backend as K\n",
    "#from keras.applications import ResNet50,Xception,VGG16,VGG19\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from plotcm import plotcm\n",
    "\n",
    "####\n",
    "# Where to save the figures\n",
    "IMAGES_PATH = \"../images\"\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        pyplot.tight_layout()\n",
    "    pyplot.savefig(path, format=fig_extension, dpi=resolution)\n",
    "from utils import saveFigures,write_json,create_json,load_previous_weights\n",
    "\n",
    "from models import VGG16, MLP_model,VGG19,Transfer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "## ask for GPU memory gracefully\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_training_samples:  (40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train = X_train/255.\n",
    "X_valid = X_valid/255.\n",
    "X_test = X_test/255.\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_valid = np_utils.to_categorical(y_valid)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "class_names = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "print(\"num_training_samples: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration parameters\n",
    "Configuration values of different parts of the solution. You should change some of them to obtain better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/12_19_36_06/\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Randomize the initial network \n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# Directory where to store weights of the model and results\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%d_%H_%M_%S\")\n",
    "experiment_rootdir = \"./test/\"+current_time+\"/\"\n",
    "weights_path = experiment_rootdir +\"weights.h5\"\n",
    "weights_best_path = experiment_rootdir +\"weights_best.h5\"\n",
    "'''\n",
    "weights_augmentation_path = experiment_rootdir +\"weights_augmentation.h5\"\n",
    "weights_augmentation_best_path = experiment_rootdir +\"weights_augmentation_best.h5\"\n",
    "'''\n",
    "json_path = experiment_rootdir +\"experiment.json\"\n",
    "\n",
    "# Create experiment directory if it does not exists\n",
    "if not os.path.exists(experiment_rootdir):\n",
    "    os.makedirs(experiment_rootdir)\n",
    "print(experiment_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that configures the training process\n",
    "\n",
    "# Tunable parameters\n",
    "name_model = \"VGG16_data_augmentation\"\n",
    "initial_lr = 5e-2\n",
    "n_hidden = 0\n",
    "\n",
    "## Regularizarion\n",
    "l2_reg = 0\n",
    "dropout = 0\n",
    "batch_norm = False\n",
    "data_augmentation = False\n",
    "\n",
    "# Constant parameters\n",
    "compile_parameters = { \"metrics\": ['accuracy'], \"optimizer\": SGD(learning_rate=initial_lr)}\n",
    "\n",
    "batch_size = 512 \n",
    "epochs = 200\n",
    "initial_epoch = 0 \n",
    "num_classes = 10\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(weights_best_path,save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=25,restore_best_weights=True)\n",
    "'''\n",
    "optimizer=  = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "optimizer = keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "'''\n",
    "\n",
    "parameters = {\n",
    "    \"name_model\":name_model,\n",
    "    \"compile_parameters\" :str(compile_parameters) ,\n",
    "    \"l2_reg\" : l2_reg,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs, \n",
    "    \"initial_epoch\":initial_epoch, \n",
    "    \"initial_lr\": initial_lr,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"dropout\": dropout,\n",
    "    \"batch_norm\": batch_norm,\n",
    "    \"data_aug\" : data_augmentation\n",
    "}\n",
    "create_json({\"parameters\":parameters}, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,compile_parameters,X_train, y_train, validation_data, epochs, batch_size, experiment_rootdir, weights_path, json_path,datagen, callbacks,name=''):\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=compile_parameters['optimizer'], metrics=compile_parameters['metrics'])\n",
    "    print(model.summary())\n",
    "\n",
    "    history=model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                steps_per_epoch = (len(X_train)//batch_size), epochs=epochs, \n",
    "                validation_data=validation_data,\n",
    "                validation_steps=(len(X_train)*0.2//batch_size),\n",
    "                callbacks = callbacks)\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    weights_path\n",
    "    data = {\"train_result\"+name:hist_df.to_dict()}\n",
    "    \n",
    "    model.save_weights(weights_path)\n",
    "    write_json(data,json_path)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# set up image augmentation\n",
    "rotation_range=45\n",
    "horizontal_flip=True\n",
    "zoom_range=0.3\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=rotation_range if data_augmentation else 0,\n",
    "    horizontal_flip=horizontal_flip if data_augmentation else 0,\n",
    "    zoom_range=zoom_range if data_augmentation else 0)\n",
    " \n",
    "# datagen.fit(X_train)\n",
    "# for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
    "#   print (X_batch.shape)\n",
    "#   for i in range(0,4):\n",
    "#     pyplot.subplot(220 +1 +i)\n",
    "#     pyplot.imshow(X_batch[i])\n",
    "#   pyplot.show()\n",
    "#   break\n",
    "# train with image augmentation\n",
    "\n",
    "augmentation_parameters = {\n",
    "    \"used\": str(data_augmentation),\n",
    "    \"rotation_range\":str(rotation_range),\n",
    "    \"horizontal_flip\":str(horizontal_flip),\n",
    "    \"zoom_range\":str(zoom_range)\n",
    "}\n",
    "write_json({\"augmentation_parameters\":augmentation_parameters}, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible to find weight path. Returning untrained model\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 20,554,826\n",
      "Trainable params: 20,554,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "78/78 [==============================] - 110s 1s/step - loss: 2.3026 - accuracy: 0.0966 - val_loss: 2.3024 - val_accuracy: 0.0983\n",
      "Epoch 2/200\n",
      "78/78 [==============================] - 92s 1s/step - loss: 2.3026 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.0957\n",
      "Epoch 3/200\n",
      "78/78 [==============================] - 88s 1s/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0987\n",
      "Epoch 4/200\n",
      "78/78 [==============================] - 88s 1s/step - loss: 2.3026 - accuracy: 0.1025 - val_loss: 2.3023 - val_accuracy: 0.0983\n",
      "Epoch 5/200\n",
      "78/78 [==============================] - 81s 1s/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.1001\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - 76s 974ms/step - loss: 2.3025 - accuracy: 0.1056 - val_loss: 2.3022 - val_accuracy: 0.0929\n",
      "Epoch 7/200\n",
      "78/78 [==============================] - 81s 1s/step - loss: 2.3025 - accuracy: 0.1024 - val_loss: 2.3026 - val_accuracy: 0.1028\n",
      "Epoch 8/200\n",
      "78/78 [==============================] - 76s 975ms/step - loss: 2.3025 - accuracy: 0.1066 - val_loss: 2.3029 - val_accuracy: 0.0993\n",
      "Epoch 9/200\n",
      "78/78 [==============================] - 76s 977ms/step - loss: 2.3023 - accuracy: 0.1062 - val_loss: 2.3018 - val_accuracy: 0.1355\n",
      "Epoch 10/200\n",
      "78/78 [==============================] - 80s 1s/step - loss: 2.3022 - accuracy: 0.1176 - val_loss: 2.3021 - val_accuracy: 0.0965\n",
      "Epoch 11/200\n",
      "78/78 [==============================] - 76s 975ms/step - loss: 2.3020 - accuracy: 0.1113 - val_loss: 2.3025 - val_accuracy: 0.0985\n",
      "Epoch 12/200\n",
      "78/78 [==============================] - 77s 983ms/step - loss: 2.3017 - accuracy: 0.1238 - val_loss: 2.3010 - val_accuracy: 0.1426\n",
      "Epoch 13/200\n",
      "78/78 [==============================] - 76s 976ms/step - loss: 2.3012 - accuracy: 0.1373 - val_loss: 2.3012 - val_accuracy: 0.1258\n",
      "Epoch 14/200\n",
      "78/78 [==============================] - 74s 952ms/step - loss: 2.3000 - accuracy: 0.1581 - val_loss: 2.2991 - val_accuracy: 0.1765\n",
      "Epoch 15/200\n",
      "78/78 [==============================] - 75s 965ms/step - loss: 2.2972 - accuracy: 0.1622 - val_loss: 2.2944 - val_accuracy: 0.1595\n",
      "Epoch 16/200\n",
      "78/78 [==============================] - 82s 1s/step - loss: 2.2884 - accuracy: 0.1611 - val_loss: 2.2836 - val_accuracy: 0.1661\n",
      "Epoch 17/200\n",
      "78/78 [==============================] - 81s 1s/step - loss: 2.2573 - accuracy: 0.1521 - val_loss: 2.2233 - val_accuracy: 0.1620\n",
      "Epoch 18/200\n",
      "78/78 [==============================] - 82s 1s/step - loss: 2.2351 - accuracy: 0.1455 - val_loss: 2.2936 - val_accuracy: 0.1089\n",
      "Epoch 19/200\n",
      "78/78 [==============================] - 77s 984ms/step - loss: 2.1931 - accuracy: 0.1701 - val_loss: 2.1883 - val_accuracy: 0.1871\n",
      "Epoch 20/200\n",
      "78/78 [==============================] - 82s 1s/step - loss: 2.1566 - accuracy: 0.1847 - val_loss: 2.1570 - val_accuracy: 0.1972\n",
      "Epoch 21/200\n",
      "78/78 [==============================] - 93s 1s/step - loss: 2.1346 - accuracy: 0.1981 - val_loss: 2.0856 - val_accuracy: 0.2081\n",
      "Epoch 22/200\n",
      "78/78 [==============================] - 91s 1s/step - loss: 2.1098 - accuracy: 0.2102 - val_loss: 2.0453 - val_accuracy: 0.2250\n",
      "Epoch 23/200\n",
      "78/78 [==============================] - 92s 1s/step - loss: 2.0876 - accuracy: 0.2204 - val_loss: 2.2776 - val_accuracy: 0.1181\n",
      "Epoch 24/200\n",
      "78/78 [==============================] - 90s 1s/step - loss: 2.0793 - accuracy: 0.2296 - val_loss: 2.0951 - val_accuracy: 0.2336\n",
      "Epoch 25/200\n",
      "78/78 [==============================] - 91s 1s/step - loss: 2.0501 - accuracy: 0.2336 - val_loss: 2.0405 - val_accuracy: 0.2439\n",
      "Epoch 26/200\n",
      "78/78 [==============================] - 91s 1s/step - loss: 2.0395 - accuracy: 0.2421 - val_loss: 1.9864 - val_accuracy: 0.2661\n",
      "Epoch 27/200\n",
      "78/78 [==============================] - 88s 1s/step - loss: 2.0296 - accuracy: 0.2502 - val_loss: 1.9949 - val_accuracy: 0.2644\n",
      "Epoch 28/200\n",
      "78/78 [==============================] - 75s 967ms/step - loss: 2.0137 - accuracy: 0.2592 - val_loss: 1.9283 - val_accuracy: 0.2669\n",
      "Epoch 29/200\n",
      "78/78 [==============================] - 76s 979ms/step - loss: 1.9957 - accuracy: 0.2663 - val_loss: 1.9174 - val_accuracy: 0.2833\n",
      "Epoch 30/200\n",
      "78/78 [==============================] - 77s 989ms/step - loss: 1.9891 - accuracy: 0.2658 - val_loss: 1.9602 - val_accuracy: 0.2731\n",
      "Epoch 31/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.9850 - accuracy: 0.2755 - val_loss: 1.9510 - val_accuracy: 0.2852\n",
      "Epoch 32/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.9636 - accuracy: 0.2736 - val_loss: 1.9922 - val_accuracy: 0.2700\n",
      "Epoch 33/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.9635 - accuracy: 0.2749 - val_loss: 1.9427 - val_accuracy: 0.2842\n",
      "Epoch 34/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 1.9546 - accuracy: 0.2838 - val_loss: 1.9821 - val_accuracy: 0.2882\n",
      "Epoch 35/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 1.9287 - accuracy: 0.2886 - val_loss: 2.0680 - val_accuracy: 0.2366\n",
      "Epoch 36/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 1.9186 - accuracy: 0.2933 - val_loss: 2.0114 - val_accuracy: 0.2700\n",
      "Epoch 37/200\n",
      "78/78 [==============================] - 75s 962ms/step - loss: 1.9148 - accuracy: 0.2930 - val_loss: 1.9045 - val_accuracy: 0.3021\n",
      "Epoch 38/200\n",
      "78/78 [==============================] - 77s 992ms/step - loss: 1.9050 - accuracy: 0.3008 - val_loss: 1.9015 - val_accuracy: 0.2875\n",
      "Epoch 39/200\n",
      "78/78 [==============================] - 78s 995ms/step - loss: 1.8948 - accuracy: 0.3047 - val_loss: 1.8508 - val_accuracy: 0.3262\n",
      "Epoch 40/200\n",
      "78/78 [==============================] - 76s 980ms/step - loss: 1.8785 - accuracy: 0.3113 - val_loss: 1.8503 - val_accuracy: 0.3161\n",
      "Epoch 41/200\n",
      "78/78 [==============================] - 78s 999ms/step - loss: 1.8626 - accuracy: 0.3157 - val_loss: 1.8013 - val_accuracy: 0.3115\n",
      "Epoch 42/200\n",
      "78/78 [==============================] - 77s 992ms/step - loss: 1.8690 - accuracy: 0.3090 - val_loss: 1.8295 - val_accuracy: 0.3392\n",
      "Epoch 43/200\n",
      "78/78 [==============================] - 76s 974ms/step - loss: 1.8333 - accuracy: 0.3247 - val_loss: 1.8034 - val_accuracy: 0.3469\n",
      "Epoch 44/200\n",
      "78/78 [==============================] - 75s 961ms/step - loss: 1.8283 - accuracy: 0.3232 - val_loss: 1.7527 - val_accuracy: 0.3492\n",
      "Epoch 45/200\n",
      "78/78 [==============================] - 77s 990ms/step - loss: 1.8157 - accuracy: 0.3277 - val_loss: 1.7987 - val_accuracy: 0.3322\n",
      "Epoch 46/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 1.7979 - accuracy: 0.3354 - val_loss: 1.8274 - val_accuracy: 0.3351\n",
      "Epoch 47/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.7966 - accuracy: 0.3390 - val_loss: 1.6814 - val_accuracy: 0.3680\n",
      "Epoch 48/200\n",
      "78/78 [==============================] - 78s 995ms/step - loss: 1.7867 - accuracy: 0.3434 - val_loss: 1.8580 - val_accuracy: 0.3219\n",
      "Epoch 49/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.7633 - accuracy: 0.3512 - val_loss: 1.7688 - val_accuracy: 0.3711\n",
      "Epoch 50/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.7585 - accuracy: 0.3546 - val_loss: 1.7020 - val_accuracy: 0.3728\n",
      "Epoch 51/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 1.7488 - accuracy: 0.3584 - val_loss: 1.7130 - val_accuracy: 0.3894\n",
      "Epoch 52/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 1.7213 - accuracy: 0.3693 - val_loss: 1.7654 - val_accuracy: 0.3599\n",
      "Epoch 53/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.7268 - accuracy: 0.3659 - val_loss: 1.6234 - val_accuracy: 0.3915\n",
      "Epoch 54/200\n",
      "78/78 [==============================] - 76s 979ms/step - loss: 1.7134 - accuracy: 0.3710 - val_loss: 1.8500 - val_accuracy: 0.3309\n",
      "Epoch 55/200\n",
      "78/78 [==============================] - 76s 977ms/step - loss: 1.6903 - accuracy: 0.3837 - val_loss: 1.7804 - val_accuracy: 0.3425\n",
      "Epoch 56/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.6947 - accuracy: 0.3770 - val_loss: 1.6796 - val_accuracy: 0.3935\n",
      "Epoch 57/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.6833 - accuracy: 0.3848 - val_loss: 1.6654 - val_accuracy: 0.3943\n",
      "Epoch 58/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.6593 - accuracy: 0.3952 - val_loss: 1.6452 - val_accuracy: 0.4122\n",
      "Epoch 59/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 1.6518 - accuracy: 0.3952 - val_loss: 1.6195 - val_accuracy: 0.4071\n",
      "Epoch 60/200\n",
      "78/78 [==============================] - 78s 1s/step - loss: 1.6414 - accuracy: 0.3996 - val_loss: 1.8465 - val_accuracy: 0.3481\n",
      "Epoch 61/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.6426 - accuracy: 0.4029 - val_loss: 1.5881 - val_accuracy: 0.4164\n",
      "Epoch 62/200\n",
      "78/78 [==============================] - 77s 992ms/step - loss: 1.6225 - accuracy: 0.4110 - val_loss: 1.6708 - val_accuracy: 0.3909\n",
      "Epoch 63/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 1.6091 - accuracy: 0.4129 - val_loss: 1.5632 - val_accuracy: 0.4246\n",
      "Epoch 64/200\n",
      "78/78 [==============================] - 77s 992ms/step - loss: 1.6092 - accuracy: 0.4161 - val_loss: 1.6329 - val_accuracy: 0.4293\n",
      "Epoch 65/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 1.5753 - accuracy: 0.4284 - val_loss: 1.6379 - val_accuracy: 0.4132\n",
      "Epoch 66/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.5954 - accuracy: 0.4227 - val_loss: 1.5164 - val_accuracy: 0.4444\n",
      "Epoch 67/200\n",
      "78/78 [==============================] - 77s 987ms/step - loss: 1.5741 - accuracy: 0.4289 - val_loss: 1.5520 - val_accuracy: 0.4353\n",
      "Epoch 68/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.5735 - accuracy: 0.4280 - val_loss: 1.4382 - val_accuracy: 0.4522\n",
      "Epoch 69/200\n",
      "78/78 [==============================] - 77s 986ms/step - loss: 1.5425 - accuracy: 0.4392 - val_loss: 1.5456 - val_accuracy: 0.4259\n",
      "Epoch 70/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 1.5320 - accuracy: 0.4418 - val_loss: 1.4291 - val_accuracy: 0.4671\n",
      "Epoch 71/200\n",
      "78/78 [==============================] - 77s 992ms/step - loss: 1.5299 - accuracy: 0.4449 - val_loss: 1.6064 - val_accuracy: 0.4219\n",
      "Epoch 72/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.5188 - accuracy: 0.4493 - val_loss: 1.4573 - val_accuracy: 0.4699\n",
      "Epoch 73/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.5020 - accuracy: 0.4569 - val_loss: 1.4808 - val_accuracy: 0.4590\n",
      "Epoch 74/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.4875 - accuracy: 0.4606 - val_loss: 1.4715 - val_accuracy: 0.4891\n",
      "Epoch 75/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 1.4799 - accuracy: 0.4636 - val_loss: 1.4189 - val_accuracy: 0.4890\n",
      "Epoch 76/200\n",
      "78/78 [==============================] - 78s 1s/step - loss: 1.4636 - accuracy: 0.4708 - val_loss: 1.4744 - val_accuracy: 0.4485\n",
      "Epoch 77/200\n",
      "78/78 [==============================] - 76s 973ms/step - loss: 1.4608 - accuracy: 0.4702 - val_loss: 1.4747 - val_accuracy: 0.4651\n",
      "Epoch 78/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 1.4575 - accuracy: 0.4755 - val_loss: 1.4522 - val_accuracy: 0.4828\n",
      "Epoch 79/200\n",
      "78/78 [==============================] - 76s 968ms/step - loss: 1.4511 - accuracy: 0.4783 - val_loss: 1.4821 - val_accuracy: 0.4868\n",
      "Epoch 80/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.4414 - accuracy: 0.4806 - val_loss: 1.3887 - val_accuracy: 0.4819\n",
      "Epoch 81/200\n",
      "78/78 [==============================] - 77s 985ms/step - loss: 1.4164 - accuracy: 0.4901 - val_loss: 1.3553 - val_accuracy: 0.4980\n",
      "Epoch 82/200\n",
      "78/78 [==============================] - 77s 983ms/step - loss: 1.4251 - accuracy: 0.4876 - val_loss: 1.4164 - val_accuracy: 0.4978\n",
      "Epoch 83/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.4025 - accuracy: 0.4945 - val_loss: 1.4326 - val_accuracy: 0.4942\n",
      "Epoch 84/200\n",
      "78/78 [==============================] - 77s 981ms/step - loss: 1.3844 - accuracy: 0.5003 - val_loss: 1.3156 - val_accuracy: 0.4996\n",
      "Epoch 85/200\n",
      "78/78 [==============================] - 77s 981ms/step - loss: 1.3840 - accuracy: 0.5009 - val_loss: 1.3344 - val_accuracy: 0.5197\n",
      "Epoch 86/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.3720 - accuracy: 0.5031 - val_loss: 1.3285 - val_accuracy: 0.5282\n",
      "Epoch 87/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.3651 - accuracy: 0.5089 - val_loss: 1.3380 - val_accuracy: 0.5145\n",
      "Epoch 88/200\n",
      "78/78 [==============================] - 75s 968ms/step - loss: 1.3566 - accuracy: 0.5111 - val_loss: 1.4023 - val_accuracy: 0.5047\n",
      "Epoch 89/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.3561 - accuracy: 0.5134 - val_loss: 1.3956 - val_accuracy: 0.5229\n",
      "Epoch 90/200\n",
      "78/78 [==============================] - 75s 967ms/step - loss: 1.3417 - accuracy: 0.5179 - val_loss: 1.3379 - val_accuracy: 0.5035\n",
      "Epoch 91/200\n",
      "78/78 [==============================] - 76s 968ms/step - loss: 1.3240 - accuracy: 0.5227 - val_loss: 1.3141 - val_accuracy: 0.5337\n",
      "Epoch 92/200\n",
      "78/78 [==============================] - 78s 1s/step - loss: 1.3189 - accuracy: 0.5268 - val_loss: 1.4188 - val_accuracy: 0.5073\n",
      "Epoch 93/200\n",
      "78/78 [==============================] - 75s 965ms/step - loss: 1.3136 - accuracy: 0.5249 - val_loss: 1.2645 - val_accuracy: 0.5267\n",
      "Epoch 94/200\n",
      "78/78 [==============================] - 77s 988ms/step - loss: 1.2981 - accuracy: 0.5337 - val_loss: 1.3069 - val_accuracy: 0.5261\n",
      "Epoch 95/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.2901 - accuracy: 0.5409 - val_loss: 1.2634 - val_accuracy: 0.5206\n",
      "Epoch 96/200\n",
      "78/78 [==============================] - 78s 1s/step - loss: 1.2783 - accuracy: 0.5429 - val_loss: 1.2851 - val_accuracy: 0.5392\n",
      "Epoch 97/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 1.2688 - accuracy: 0.5465 - val_loss: 1.3524 - val_accuracy: 0.5625\n",
      "Epoch 98/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 1.2723 - accuracy: 0.5429 - val_loss: 1.2745 - val_accuracy: 0.5262\n",
      "Epoch 99/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.2642 - accuracy: 0.5477 - val_loss: 1.1703 - val_accuracy: 0.5575\n",
      "Epoch 100/200\n",
      "78/78 [==============================] - 77s 984ms/step - loss: 1.2509 - accuracy: 0.5528 - val_loss: 1.3546 - val_accuracy: 0.5374\n",
      "Epoch 101/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 1.2278 - accuracy: 0.5610 - val_loss: 1.2161 - val_accuracy: 0.5473\n",
      "Epoch 102/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 1.2313 - accuracy: 0.5575 - val_loss: 1.2485 - val_accuracy: 0.5641\n",
      "Epoch 103/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.2190 - accuracy: 0.5670 - val_loss: 1.0643 - val_accuracy: 0.5761\n",
      "Epoch 104/200\n",
      "78/78 [==============================] - 77s 991ms/step - loss: 1.2124 - accuracy: 0.5661 - val_loss: 1.1373 - val_accuracy: 0.5722\n",
      "Epoch 105/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.1851 - accuracy: 0.5772 - val_loss: 1.1182 - val_accuracy: 0.5612\n",
      "Epoch 106/200\n",
      "78/78 [==============================] - 76s 980ms/step - loss: 1.1823 - accuracy: 0.5795 - val_loss: 1.1342 - val_accuracy: 0.5589\n",
      "Epoch 107/200\n",
      "78/78 [==============================] - 75s 961ms/step - loss: 1.1893 - accuracy: 0.5746 - val_loss: 1.2764 - val_accuracy: 0.5520\n",
      "Epoch 108/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 1.1543 - accuracy: 0.5891 - val_loss: 1.2242 - val_accuracy: 0.5816\n",
      "Epoch 109/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 1.1607 - accuracy: 0.5859 - val_loss: 1.1786 - val_accuracy: 0.5863\n",
      "Epoch 110/200\n",
      "78/78 [==============================] - 75s 963ms/step - loss: 1.1561 - accuracy: 0.5903 - val_loss: 1.1409 - val_accuracy: 0.5919\n",
      "Epoch 111/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.1369 - accuracy: 0.5953 - val_loss: 1.2141 - val_accuracy: 0.5871\n",
      "Epoch 112/200\n",
      "78/78 [==============================] - 76s 968ms/step - loss: 1.1246 - accuracy: 0.5972 - val_loss: 1.2857 - val_accuracy: 0.5827\n",
      "Epoch 113/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.1171 - accuracy: 0.6033 - val_loss: 1.2466 - val_accuracy: 0.5658\n",
      "Epoch 114/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.1060 - accuracy: 0.6079 - val_loss: 1.1587 - val_accuracy: 0.6081\n",
      "Epoch 115/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 1.0942 - accuracy: 0.6095 - val_loss: 1.1979 - val_accuracy: 0.5927\n",
      "Epoch 116/200\n",
      "78/78 [==============================] - 76s 977ms/step - loss: 1.0783 - accuracy: 0.6163 - val_loss: 1.0551 - val_accuracy: 0.5871\n",
      "Epoch 117/200\n",
      "78/78 [==============================] - 77s 984ms/step - loss: 1.0834 - accuracy: 0.6163 - val_loss: 1.1018 - val_accuracy: 0.5964\n",
      "Epoch 118/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 1.0866 - accuracy: 0.6135 - val_loss: 1.1640 - val_accuracy: 0.6071\n",
      "Epoch 119/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.0563 - accuracy: 0.6244 - val_loss: 1.3618 - val_accuracy: 0.5509\n",
      "Epoch 120/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.0518 - accuracy: 0.6291 - val_loss: 1.0680 - val_accuracy: 0.5977\n",
      "Epoch 121/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 1.0430 - accuracy: 0.6302 - val_loss: 1.0935 - val_accuracy: 0.6132\n",
      "Epoch 122/200\n",
      "78/78 [==============================] - 76s 980ms/step - loss: 1.0203 - accuracy: 0.6399 - val_loss: 1.0684 - val_accuracy: 0.6258\n",
      "Epoch 123/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 1.0143 - accuracy: 0.6409 - val_loss: 1.0926 - val_accuracy: 0.6116\n",
      "Epoch 124/200\n",
      "78/78 [==============================] - 75s 963ms/step - loss: 1.0173 - accuracy: 0.6397 - val_loss: 1.0576 - val_accuracy: 0.6206\n",
      "Epoch 125/200\n",
      "78/78 [==============================] - 76s 980ms/step - loss: 0.9892 - accuracy: 0.6508 - val_loss: 1.1060 - val_accuracy: 0.6210\n",
      "Epoch 126/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 0.9955 - accuracy: 0.6488 - val_loss: 1.1079 - val_accuracy: 0.6125\n",
      "Epoch 127/200\n",
      "78/78 [==============================] - 76s 969ms/step - loss: 0.9756 - accuracy: 0.6550 - val_loss: 1.1067 - val_accuracy: 0.6331\n",
      "Epoch 128/200\n",
      "78/78 [==============================] - 75s 961ms/step - loss: 0.9808 - accuracy: 0.6534 - val_loss: 1.0735 - val_accuracy: 0.6461\n",
      "Epoch 129/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 0.9677 - accuracy: 0.6574 - val_loss: 1.0514 - val_accuracy: 0.6529\n",
      "Epoch 130/200\n",
      "78/78 [==============================] - 78s 998ms/step - loss: 0.9482 - accuracy: 0.6667 - val_loss: 1.0501 - val_accuracy: 0.6169\n",
      "Epoch 131/200\n",
      "78/78 [==============================] - 77s 988ms/step - loss: 0.9317 - accuracy: 0.6685 - val_loss: 1.0803 - val_accuracy: 0.6315\n",
      "Epoch 132/200\n",
      "78/78 [==============================] - 75s 959ms/step - loss: 0.9619 - accuracy: 0.6640 - val_loss: 0.9601 - val_accuracy: 0.6434\n",
      "Epoch 133/200\n",
      "78/78 [==============================] - 77s 986ms/step - loss: 0.9114 - accuracy: 0.6786 - val_loss: 0.9986 - val_accuracy: 0.6525\n",
      "Epoch 134/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 0.9152 - accuracy: 0.6788 - val_loss: 1.0271 - val_accuracy: 0.6387\n",
      "Epoch 135/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 0.8945 - accuracy: 0.6852 - val_loss: 1.1830 - val_accuracy: 0.6144\n",
      "Epoch 136/200\n",
      "78/78 [==============================] - 75s 960ms/step - loss: 0.9208 - accuracy: 0.6751 - val_loss: 0.9672 - val_accuracy: 0.6523\n",
      "Epoch 137/200\n",
      "78/78 [==============================] - 77s 982ms/step - loss: 0.8847 - accuracy: 0.6896 - val_loss: 0.9536 - val_accuracy: 0.6600\n",
      "Epoch 138/200\n",
      "78/78 [==============================] - 77s 987ms/step - loss: 0.8924 - accuracy: 0.6866 - val_loss: 0.9770 - val_accuracy: 0.6601\n",
      "Epoch 139/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 0.8735 - accuracy: 0.6953 - val_loss: 1.0033 - val_accuracy: 0.6546\n",
      "Epoch 140/200\n",
      "78/78 [==============================] - 75s 967ms/step - loss: 0.8708 - accuracy: 0.6937 - val_loss: 0.9922 - val_accuracy: 0.6700\n",
      "Epoch 141/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 0.8611 - accuracy: 0.7010 - val_loss: 0.9803 - val_accuracy: 0.6661\n",
      "Epoch 142/200\n",
      "78/78 [==============================] - 75s 962ms/step - loss: 0.8615 - accuracy: 0.6978 - val_loss: 1.0244 - val_accuracy: 0.6649\n",
      "Epoch 143/200\n",
      "78/78 [==============================] - 76s 980ms/step - loss: 0.8286 - accuracy: 0.7092 - val_loss: 0.9706 - val_accuracy: 0.6696\n",
      "Epoch 144/200\n",
      "78/78 [==============================] - 76s 968ms/step - loss: 0.8488 - accuracy: 0.7043 - val_loss: 0.9483 - val_accuracy: 0.6702\n",
      "Epoch 145/200\n",
      "78/78 [==============================] - 77s 985ms/step - loss: 0.8408 - accuracy: 0.7056 - val_loss: 1.1495 - val_accuracy: 0.6630\n",
      "Epoch 146/200\n",
      "78/78 [==============================] - 75s 962ms/step - loss: 0.8311 - accuracy: 0.7079 - val_loss: 1.0652 - val_accuracy: 0.6267\n",
      "Epoch 147/200\n",
      "78/78 [==============================] - 77s 981ms/step - loss: 0.8044 - accuracy: 0.7169 - val_loss: 0.9579 - val_accuracy: 0.6790\n",
      "Epoch 148/200\n",
      "78/78 [==============================] - 75s 968ms/step - loss: 0.8058 - accuracy: 0.7202 - val_loss: 1.0006 - val_accuracy: 0.6746\n",
      "Epoch 149/200\n",
      "78/78 [==============================] - 73s 930ms/step - loss: 0.8000 - accuracy: 0.7201 - val_loss: 0.7888 - val_accuracy: 0.6913\n",
      "Epoch 150/200\n",
      "78/78 [==============================] - 82s 1s/step - loss: 0.8044 - accuracy: 0.7219 - val_loss: 0.8629 - val_accuracy: 0.6961\n",
      "Epoch 151/200\n",
      "78/78 [==============================] - 77s 987ms/step - loss: 0.7912 - accuracy: 0.7225 - val_loss: 0.9282 - val_accuracy: 0.6832\n",
      "Epoch 152/200\n",
      "78/78 [==============================] - 77s 987ms/step - loss: 0.7746 - accuracy: 0.7273 - val_loss: 0.9779 - val_accuracy: 0.6723\n",
      "Epoch 153/200\n",
      "78/78 [==============================] - 77s 988ms/step - loss: 0.7651 - accuracy: 0.7329 - val_loss: 0.7857 - val_accuracy: 0.7031\n",
      "Epoch 154/200\n",
      "78/78 [==============================] - 81s 1s/step - loss: 0.7757 - accuracy: 0.7289 - val_loss: 0.8925 - val_accuracy: 0.6737\n",
      "Epoch 155/200\n",
      "78/78 [==============================] - 77s 989ms/step - loss: 0.7556 - accuracy: 0.7385 - val_loss: 0.9524 - val_accuracy: 0.6651\n",
      "Epoch 156/200\n",
      "78/78 [==============================] - 77s 987ms/step - loss: 0.7582 - accuracy: 0.7355 - val_loss: 0.9050 - val_accuracy: 0.7004\n",
      "Epoch 157/200\n",
      "78/78 [==============================] - 76s 973ms/step - loss: 0.7615 - accuracy: 0.7362 - val_loss: 0.9001 - val_accuracy: 0.6862\n",
      "Epoch 158/200\n",
      "78/78 [==============================] - 76s 971ms/step - loss: 0.7655 - accuracy: 0.7341 - val_loss: 0.8838 - val_accuracy: 0.7031\n",
      "Epoch 159/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 0.7251 - accuracy: 0.7463 - val_loss: 0.9661 - val_accuracy: 0.7012\n",
      "Epoch 160/200\n",
      "78/78 [==============================] - 76s 968ms/step - loss: 0.7411 - accuracy: 0.7411 - val_loss: 0.8713 - val_accuracy: 0.7070\n",
      "Epoch 161/200\n",
      "78/78 [==============================] - 76s 970ms/step - loss: 0.7330 - accuracy: 0.7439 - val_loss: 0.8443 - val_accuracy: 0.6995\n",
      "Epoch 162/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 0.7140 - accuracy: 0.7502 - val_loss: 0.9104 - val_accuracy: 0.7118\n",
      "Epoch 163/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 0.6996 - accuracy: 0.7559 - val_loss: 0.9882 - val_accuracy: 0.6965\n",
      "Epoch 164/200\n",
      "78/78 [==============================] - 76s 972ms/step - loss: 0.6942 - accuracy: 0.7570 - val_loss: 0.8990 - val_accuracy: 0.7207\n",
      "Epoch 165/200\n",
      "78/78 [==============================] - 76s 975ms/step - loss: 0.7073 - accuracy: 0.7525 - val_loss: 0.8721 - val_accuracy: 0.6992\n",
      "Epoch 166/200\n",
      "78/78 [==============================] - 76s 980ms/step - loss: 0.6895 - accuracy: 0.7597 - val_loss: 0.8295 - val_accuracy: 0.7167\n",
      "Epoch 167/200\n",
      "78/78 [==============================] - 75s 961ms/step - loss: 0.6999 - accuracy: 0.7547 - val_loss: 0.8337 - val_accuracy: 0.7184\n",
      "Epoch 168/200\n",
      "78/78 [==============================] - 76s 973ms/step - loss: 0.6974 - accuracy: 0.7583 - val_loss: 0.8992 - val_accuracy: 0.7200\n",
      "Epoch 169/200\n",
      "78/78 [==============================] - 77s 981ms/step - loss: 0.6627 - accuracy: 0.7698 - val_loss: 0.8748 - val_accuracy: 0.6836\n",
      "Epoch 170/200\n",
      "78/78 [==============================] - 71s 910ms/step - loss: 0.6717 - accuracy: 0.7677 - val_loss: 1.0915 - val_accuracy: 0.6344\n",
      "Epoch 171/200\n",
      "78/78 [==============================] - 77s 982ms/step - loss: 0.6764 - accuracy: 0.7658 - val_loss: 0.8567 - val_accuracy: 0.7212\n",
      "Epoch 172/200\n",
      "78/78 [==============================] - 76s 980ms/step - loss: 0.6593 - accuracy: 0.7687 - val_loss: 0.7892 - val_accuracy: 0.7121\n",
      "Epoch 173/200\n",
      "78/78 [==============================] - 77s 983ms/step - loss: 0.6566 - accuracy: 0.7717 - val_loss: 0.7994 - val_accuracy: 0.7289\n",
      "Epoch 174/200\n",
      "78/78 [==============================] - 77s 982ms/step - loss: 0.6463 - accuracy: 0.7756 - val_loss: 0.7688 - val_accuracy: 0.7289\n",
      "Epoch 175/200\n",
      "78/78 [==============================] - 82s 1s/step - loss: 0.6533 - accuracy: 0.7721 - val_loss: 0.7768 - val_accuracy: 0.7246\n",
      "Epoch 176/200\n",
      "78/78 [==============================] - 77s 981ms/step - loss: 0.6375 - accuracy: 0.7773 - val_loss: 0.8736 - val_accuracy: 0.7175\n",
      "Epoch 177/200\n",
      "78/78 [==============================] - 77s 982ms/step - loss: 0.6229 - accuracy: 0.7855 - val_loss: 1.2405 - val_accuracy: 0.6654\n",
      "Epoch 178/200\n",
      "78/78 [==============================] - 72s 928ms/step - loss: 0.6192 - accuracy: 0.7854 - val_loss: 0.8502 - val_accuracy: 0.7227\n",
      "Epoch 179/200\n",
      "78/78 [==============================] - 76s 975ms/step - loss: 0.6232 - accuracy: 0.7808 - val_loss: 1.5201 - val_accuracy: 0.5785\n",
      "Epoch 180/200\n",
      "78/78 [==============================] - 78s 994ms/step - loss: 0.6337 - accuracy: 0.7795 - val_loss: 0.9295 - val_accuracy: 0.6915\n",
      "Epoch 181/200\n",
      "78/78 [==============================] - 77s 988ms/step - loss: 0.6068 - accuracy: 0.7897 - val_loss: 0.9058 - val_accuracy: 0.7145\n",
      "Epoch 182/200\n",
      "78/78 [==============================] - 77s 985ms/step - loss: 0.6159 - accuracy: 0.7868 - val_loss: 0.8709 - val_accuracy: 0.7356\n",
      "Epoch 183/200\n",
      "78/78 [==============================] - 76s 977ms/step - loss: 0.6191 - accuracy: 0.7847 - val_loss: 0.8611 - val_accuracy: 0.7270\n",
      "Epoch 184/200\n",
      "78/78 [==============================] - 77s 985ms/step - loss: 0.5897 - accuracy: 0.7936 - val_loss: 0.7917 - val_accuracy: 0.7339\n",
      "Epoch 185/200\n",
      "78/78 [==============================] - 78s 1s/step - loss: 0.5901 - accuracy: 0.7959 - val_loss: 0.8689 - val_accuracy: 0.7298\n",
      "Epoch 186/200\n",
      "78/78 [==============================] - 77s 984ms/step - loss: 0.5906 - accuracy: 0.7947 - val_loss: 0.8047 - val_accuracy: 0.7060\n",
      "Epoch 187/200\n",
      "78/78 [==============================] - 77s 986ms/step - loss: 0.5829 - accuracy: 0.7968 - val_loss: 0.7942 - val_accuracy: 0.7379\n",
      "Epoch 188/200\n",
      "78/78 [==============================] - 72s 928ms/step - loss: 0.5677 - accuracy: 0.8012 - val_loss: 0.6629 - val_accuracy: 0.7379\n",
      "Epoch 189/200\n",
      "78/78 [==============================] - 80s 1s/step - loss: 0.5772 - accuracy: 0.7999 - val_loss: 0.7309 - val_accuracy: 0.7242\n",
      "Epoch 190/200\n",
      "78/78 [==============================] - 77s 984ms/step - loss: 0.5755 - accuracy: 0.7997 - val_loss: 0.8729 - val_accuracy: 0.7344\n",
      "Epoch 191/200\n",
      "78/78 [==============================] - 78s 1s/step - loss: 0.5610 - accuracy: 0.8031 - val_loss: 0.8060 - val_accuracy: 0.7267\n",
      "Epoch 192/200\n",
      "78/78 [==============================] - 78s 997ms/step - loss: 0.5381 - accuracy: 0.8129 - val_loss: 0.6920 - val_accuracy: 0.7431\n",
      "Epoch 193/200\n",
      "78/78 [==============================] - 77s 989ms/step - loss: 0.5502 - accuracy: 0.8075 - val_loss: 0.8553 - val_accuracy: 0.7458\n",
      "Epoch 194/200\n",
      "78/78 [==============================] - 77s 988ms/step - loss: 0.5433 - accuracy: 0.8102 - val_loss: 0.7724 - val_accuracy: 0.7242\n",
      "Epoch 195/200\n",
      "78/78 [==============================] - 77s 988ms/step - loss: 0.5624 - accuracy: 0.8076 - val_loss: 0.8308 - val_accuracy: 0.7347\n",
      "Epoch 196/200\n",
      "78/78 [==============================] - 76s 978ms/step - loss: 0.5636 - accuracy: 0.8048 - val_loss: 0.7129 - val_accuracy: 0.7371\n",
      "Epoch 197/200\n",
      "78/78 [==============================] - 77s 993ms/step - loss: 0.5308 - accuracy: 0.8166 - val_loss: 0.8045 - val_accuracy: 0.7363\n",
      "Epoch 198/200\n",
      "78/78 [==============================] - 77s 986ms/step - loss: 0.5285 - accuracy: 0.8153 - val_loss: 0.7980 - val_accuracy: 0.7363\n",
      "Epoch 199/200\n",
      "78/78 [==============================] - 75s 959ms/step - loss: 0.5304 - accuracy: 0.8166 - val_loss: 0.7979 - val_accuracy: 0.7222\n",
      "Epoch 200/200\n",
      "78/78 [==============================] - 77s 981ms/step - loss: 0.5222 - accuracy: 0.8183 - val_loss: 0.7376 - val_accuracy: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif data_augmentation ==True:\\n    #load weights\\n    load_previous_weights(model,weights_best_path)\\n\\n    checkpoint_cb = ModelCheckpoint(weights_augmentation_best_path,save_best_only=True)\\n    early_stopping_cb = EarlyStopping(patience=25,restore_best_weights=True, monitor=\"val_accuracy\")\\n\\n    #training model\\n    val = datagen.flow(X_valid, y_valid, batch_size=batch_size)\\n    #val =(X_valid, y_valid)\\n    \\n    history = trainModel(model,compile_parameters,X_train, y_train, val, epochs, batch_size,experiment_rootdir,weights_augmentation_path,json_path,datagen, [checkpoint_cb,early_stopping_cb],\"_augmentation\")\\n    saveFigures(experiment_rootdir, history, \"accuracy_augmentation\", \"loss_augmentation\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get model\n",
    "#model = MLP_model(dropout, num_classes=10, img_width=32, img_height=32, img_channels=3,l2_reg= l2_reg,n_hidden=n_hidden, batch_norm=batch_norm)\n",
    "model = VGG16(dropout, num_classes=10, img_width=32, img_height=32, img_channels=3,l2_reg=l2_reg,batch_norm = batch_norm)\n",
    "#model = Transfer_model(dropout, img_width=32, img_height=32, img_channels=3, num_classes=10,l2_reg=l2_reg, batch_norm = batch_norm)\n",
    "#load weights\n",
    "load_previous_weights(model,weights_best_path)\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(weights_best_path,save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=25,restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "\n",
    "#training model\n",
    "val = datagen.flow(X_valid, y_valid, batch_size=batch_size)\n",
    "#val =(X_valid, y_valid)\n",
    "history = trainModel(model,compile_parameters,X_train, y_train, val, epochs, batch_size,experiment_rootdir,weights_path,json_path,datagen, [checkpoint_cb,early_stopping_cb])\n",
    "saveFigures(experiment_rootdir, history, \"accuracy\", \"loss\")\n",
    "'''\n",
    "if data_augmentation ==True:\n",
    "    #load weights\n",
    "    load_previous_weights(model,weights_best_path)\n",
    "\n",
    "    checkpoint_cb = ModelCheckpoint(weights_augmentation_best_path,save_best_only=True)\n",
    "    early_stopping_cb = EarlyStopping(patience=25,restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "\n",
    "    #training model\n",
    "    val = datagen.flow(X_valid, y_valid, batch_size=batch_size)\n",
    "    #val =(X_valid, y_valid)\n",
    "    \n",
    "    history = trainModel(model,compile_parameters,X_train, y_train, val, epochs, batch_size,experiment_rootdir,weights_augmentation_path,json_path,datagen, [checkpoint_cb,early_stopping_cb],\"_augmentation\")\n",
    "    saveFigures(experiment_rootdir, history, \"accuracy_augmentation\", \"loss_augmentation\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Evaluation:\n",
      "Average accuracy =  0.7521\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "gt = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Evaluate predictions: Average accuracy and highest errors\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Evaluation:\")\n",
    "# Compute average accuracy\n",
    "ave_accuracy = metrics.accuracy_score(gt, y_pred)\n",
    "print('Average accuracy = ', ave_accuracy)\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "# Visualize confusion matrix                                           \n",
    "plotcm(experiment_rootdir, gt, y_pred,class_names, experiment_rootdir, normalize=True)\n",
    "\n",
    "data = {\"test_accuracy\":ave_accuracy}\n",
    "write_json(data,json_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install playsound\n",
    "\n",
    "#from playsound import playsound\n",
    "#playsound('./sonido_fin.mp3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
